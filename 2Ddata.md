# 2-dimensional Data and Sequence Learning

## Speech

|Paper title|Year|Published at|Category|URLs|
|-----------|----|------------|--------|----|
|Deep Speech: Scaling up end-to-end speech recognition|2014|Arxiv|ASR|[PDF](https://arxiv.org/pdf/1412.5567.pdf)|
|Long short-term memory recurrent neural network architectures for large scale acoustic modeling|2014|InterSpeech|ASR|[PDF](https://pdfs.semanticscholar.org/c85d/46a94768bdcf7ffcb844b47c5b8e8e8234a3.pdf?_ga=1.8585459.730356906.1493526584)|
|Deep neural networks for small footprint text-dependent speaker verification|2014|ICASSP|Speaker Verification|[PDF](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6854363)|
|Towards End-to-End Speech Recognition with Recurrent Neural Networks|2014|ICML|ASR|[PDF](https://pdfs.semanticscholar.org/0fa5/53cfa0cf3cbdf7a913aa2ae789a757dfb32f.pdf?_ga=1.214035281.730356906.1493526584)|
|Attention-Based Models for Speech Recognition|2015|NIPS|ASR|[PDF](https://pdfs.semanticscholar.org/b624/504240fa52ab76167acfe3156150ca01cf3b.pdf?_ga=1.50080608.730356906.1493526584)|
|Convolutional, Long Short-Term Memory, fully connected Deep Neural Networks|2015|ICASSP|ASR|[PDF](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7178838)|
|TTS synthesis with bidirectional LSTM based recurrent neural networks|2014|InterSpeech|TTS|[PDF]()|
|Voice conversion using deep Bidirectional Long Short-Term Memory based Recurrent Neural Networks|2015|ICASSP|Voice Conversion|[PDF](https://ieeexplore.ieee.org/document/7178896)|
|End-to-end attention-based large vocabulary speech recognition|2016|ICASSP|ASR|[PDF](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7472618)|
|Listen, attend and spell: A neural network for large vocabulary conversational speech recognition|2016|ICASSP|ASR|[PDF](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7472621)|
|Very Deep Convolutional Networks for End-to-End Speech Recognition|2016|ICASSP|ASR|[PDF](https://arxiv.org/pdf/1610.03022.pdf)|
|WaveNet: A Generative Model for Raw Audio|2016|SSW|ASR|[PDF](https://arxiv.org/pdf/1609.03499.pdf)|
|Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning|2017|ICASSP|ASR|[PDF](https://arxiv.org/pdf/1609.06773.pdf)|
|ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA|2017|FPGA|ASR, Efficient DL|[PDF](http://dl.acm.org/citation.cfm?id=3021745)|
|SampleRNN: An Unconditional End-to-End Neural Audio Generation Model|2017|ICLR|TTS|[PDF](https://arxiv.org/pdf/1612.07837.pdf)|
|Char2Wav: End-to-end speech synthesis|2017|ICLR (workshop)|TTS|[PDF](https://openreview.net/forum?id=B1VWyySKx)|
|Deep Voice: Real-time Neural Text-to-Speech|2017|ICML|TTS|[PDF](https://arxiv.org/pdf/1702.07825.pdf)|
|Deep Voice 2: Multi-Speaker Neural Text-to-Speech|2017|NIPS|[PDF](https://arxiv.org/pdf/1705.08947)|
|Deep Neural Network Embeddings for Text-Independent Speaker Verification|2017|InterSpeech|Speaker Verification|[PDF](https://pdfs.semanticscholar.org/3697/28d7576683a25de8890e4bc02fae6132fccb.pdf)|
|Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions|2018|ICASSP|TTS|[PDF](https://arxiv.org/pdf/1712.05884)|
|State-of-the-art Speech Recognition With Sequence-to-Sequence Models|2018|ICASSP|ASR|[PDF](https://arxiv.org/pdf/1712.01769)|
|Parallel WaveNet: Fast High-Fidelity Speech Synthesis|2018|ICML|TTS|[PDF](https://arxiv.org/pdf/1711.10433)|
|Tacotron: Towards End-to-End Speech Synthesis|2018|ICML|TTS|[PDF]()|
|Neural Voice Cloning with a Few Samples|2018|NIPS|TTS|[PDF](https://arxiv.org/pdf/1802.06006.pdf)|
|Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis|2018|NIPS|TTS|[PDF](https://arxiv.org/pdf/1806.04558.pdf)|
|Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis|2018|ICML|TTS|[PDF](https://arxiv.org/pdf/1803.09017.pdf)|
|Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron|2018|ICML|TTS|[PDF](https://arxiv.org/pdf/1803.09047)|
|FastSpeech: Fast, Robust and Controllable Text to Speech|2019|NIPS|TTS|[PDF](https://arxiv.org/pdf/1905.09263.pdf)|
|MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis|2019|NIPS|TTS|[PDF](https://arxiv.org/pdf/1910.06711.pdf)|
|Waveglow: A flow-based generative network for speech synthesis|2019|ICASSP|TTS|[PDF](https://arxiv.org/pdf/1811.00002.pdf)|
|AutoVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss|2019|ICML|Voice Conversion|[PDF](http://proceedings.mlr.press/v97/qian19c.html)|
|LPCNet: Improving Neural Speech Synthesis Through Linear Prediction|2019|ICASSP|TTS|[PDF](https://arxiv.org/pdf/1810.11846)|
|FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow|2019|EMNLP/IJCNLP|Other|[PDF](https://arxiv.org/pdf/1909.02480)|
|Flow-TTS: A Non-Autoregressive Network for Text to Speech Based on Flow|2020|ICASSP|TTS|[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9054484)|
|Fully-hierarchical fine-grained prosody modeling for interpretable speech synthesis|2020|ICASSP|TTS|[PDF](https://arxiv.org/pdf/2002.03785)|
|Location-Relative Attention Mechanisms For Robust Long-Form Speech Synthesi|2020|ICASSP|TTS|[PDF](https://arxiv.org/pdf/1910.10288)|
|A Study of Non-autoregressive Model for Sequence Generation|2020|ACL|Sequence Generation|[PDF](https://www.aclweb.org/anthology/2020.acl-main.15.pdf)|

## Time Series

|Paper Title|Year|Published at|URLs|
|-----------|----|------------|----|
|Temporal Regularized Matrix Factorization for High-dimensional Time Series Prediction|2016|NIPS|[PDF](https://papers.nips.cc/paper/6160-temporal-regularized-matrix-factorization-for-high-dimensional-time-series-prediction)|
|Deep learning with long short-term memory networks for financial market predictions|2018|European Journal of Operational Research|[PDF](https://www.econstor.eu/bitstream/10419/157808/1/886576210.pdf)|
|Forecasting Treatment Responses Over Time Using Recurrent Marginal Structural Networks|2018|NIPS|[PDF](http://papers.nips.cc/paper/7977-forecasting-treatment-responses-over-time-using-recurrent-marginal-structural-networks.pdf), [Code](https://github.com/sjblim/rmsn_nips_2018)|
|Modeling Long- and Short-Term Temporal Patterns with Deep Neural Networks|2018|SIGIR|[PDF](https://arxiv.org/pdf/1703.07015.pdf), [Code](https://github.com/laiguokun/LSTNet)|
|Diffusion Convolutional Recurrent Neural Network: Data-Driven Traffic Forecasting|2018|ICLR|[PDF](https://arxiv.org/pdf/1707.01926.pdf), [Code](https://github.com/liyaguang/DCRNN)|
|Deep State Space Models for Time Series Forecasting|2018|NIPS|[PDF](https://papers.nips.cc/paper/8004-deep-state-space-models-for-time-series-forecasting.pdf)|
|Attend and Diagnose: Clinical Time Series Analysis Using Attention Models|2018|AAAI|[PDF](https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/viewFile/16325/16790)|
|Deep learning for time series classification: a review|2019|Data Mining and Knowledge Discovery|[PDF](https://arxiv.org/abs/1809.04356)|
|Deep Factors for Forecasting|2019|ICML|[PDF](https://arxiv.org/pdf/1905.12417.pdf)|
|SOM-VAE: Interpretable Discrete Representation Learning on Time Series|2019|ICLR|[PDF](https://openreview.net/pdf?id=rygjcsR9Y7)|
|Think Globally, Act Locally: A Deep Neural Network Approach to High-Dimensional Time Series Forecasting|2019|NIPS|[PDF](https://arxiv.org/pdf/1905.03806.pdf)|
|Forecasting Big Time Series: Theory and Practice|2019|KDD|[PDF](https://dl.acm.org/doi/pdf/10.1145/3292500.3332289)|
|Time Series Forecasting With Deep Learning: A Survey|2020|N.A.|[PDF](https://arxiv.org/pdf/2004.13408.pdf)|
