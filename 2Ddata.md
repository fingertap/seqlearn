# 2-dimensional Data and Sequence Learning

## Speech

|Paper title|Year|Published at|Category|URLs|
|-----------|----|------------|--------|----|
|Deep Speech: Scaling up end-to-end speech recognition|2014|Arxiv|ASR|[PDF](https://arxiv.org/pdf/1412.5567.pdf)|
|Long short-term memory recurrent neural network architectures for large scale acoustic modeling|2014|InterSpeech|ASR|[PDF](https://pdfs.semanticscholar.org/c85d/46a94768bdcf7ffcb844b47c5b8e8e8234a3.pdf?_ga=1.8585459.730356906.1493526584)|
|Deep neural networks for small footprint text-dependent speaker verification|2014|ICASSP|Speaker Verification|[PDF](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6854363)|
|Towards End-to-End Speech Recognition with Recurrent Neural Networks|2014|ICML|ASR|[PDF](https://pdfs.semanticscholar.org/0fa5/53cfa0cf3cbdf7a913aa2ae789a757dfb32f.pdf?_ga=1.214035281.730356906.1493526584)|
|Attention-Based Models for Speech Recognition|2015|NIPS|ASR|[PDF](https://pdfs.semanticscholar.org/b624/504240fa52ab76167acfe3156150ca01cf3b.pdf?_ga=1.50080608.730356906.1493526584)|
|Convolutional, Long Short-Term Memory, fully connected Deep Neural Networks|2015|ICASSP|ASR|[PDF](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7178838)|
|TTS synthesis with bidirectional LSTM based recurrent neural networks|2014|InterSpeech|TTS|[PDF]()|
|Voice conversion using deep Bidirectional Long Short-Term Memory based Recurrent Neural Networks|2015|ICASSP|Voice Conversion|[PDF](https://ieeexplore.ieee.org/document/7178896)|
|End-to-end attention-based large vocabulary speech recognition|2016|ICASSP|ASR|[PDF](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7472618)|
|Listen, attend and spell: A neural network for large vocabulary conversational speech recognition|2016|ICASSP|ASR|[PDF](http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7472621)|
|Very Deep Convolutional Networks for End-to-End Speech Recognition|2016|ICASSP|ASR|[PDF](https://arxiv.org/pdf/1610.03022.pdf)|
|WaveNet: A Generative Model for Raw Audio|2016|SSW|ASR|[PDF](https://arxiv.org/pdf/1609.03499.pdf)|
|Joint CTC-Attention based End-to-End Speech Recognition using Multi-task Learning|2017|ICASSP|ASR|[PDF](https://arxiv.org/pdf/1609.06773.pdf)|
|ESE: Efficient Speech Recognition Engine with Sparse LSTM on FPGA|2017|FPGA|ASR, Efficient DL|[PDF](http://dl.acm.org/citation.cfm?id=3021745)|
|SampleRNN: An Unconditional End-to-End Neural Audio Generation Model|2017|ICLR|TTS|[PDF](https://arxiv.org/pdf/1612.07837.pdf)|
|Char2Wav: End-to-end speech synthesis|2017|ICLR (workshop)|TTS|[PDF](https://openreview.net/forum?id=B1VWyySKx)|
|Deep Voice: Real-time Neural Text-to-Speech|2017|ICML|TTS|[PDF](https://arxiv.org/pdf/1702.07825.pdf)|
|Deep Voice 2: Multi-Speaker Neural Text-to-Speech|2017|NIPS|[PDF](https://arxiv.org/pdf/1705.08947)|
|Deep Neural Network Embeddings for Text-Independent Speaker Verification|2017|InterSpeech|Speaker Verification|[PDF](https://pdfs.semanticscholar.org/3697/28d7576683a25de8890e4bc02fae6132fccb.pdf)|
|Natural TTS Synthesis by Conditioning WaveNet on Mel Spectrogram Predictions|2018|ICASSP|TTS|[PDF](https://arxiv.org/pdf/1712.05884)|
|State-of-the-art Speech Recognition With Sequence-to-Sequence Models|2018|ICASSP|ASR|[PDF](https://arxiv.org/pdf/1712.01769)|
|Parallel WaveNet: Fast High-Fidelity Speech Synthesis|2018|ICML|TTS|[PDF](https://arxiv.org/pdf/1711.10433)|
|Tacotron: Towards End-to-End Speech Synthesis|2018|ICML|TTS|[PDF]()|
|Neural Voice Cloning with a Few Samples|2018|NIPS|TTS|[PDF](https://arxiv.org/pdf/1802.06006.pdf)|
|Transfer Learning from Speaker Verification to Multispeaker Text-To-Speech Synthesis|2018|NIPS|TTS|[PDF](https://arxiv.org/pdf/1806.04558.pdf)|
|Style Tokens: Unsupervised Style Modeling, Control and Transfer in End-to-End Speech Synthesis|2018|ICML|TTS|[PDF](https://arxiv.org/pdf/1803.09017.pdf)|
|Towards End-to-End Prosody Transfer for Expressive Speech Synthesis with Tacotron|2018|ICML|TTS|[PDF](https://arxiv.org/pdf/1803.09047)|
|FastSpeech: Fast, Robust and Controllable Text to Speech|2019|NIPS|TTS|[PDF](https://arxiv.org/pdf/1905.09263.pdf)|
|MelGAN: Generative Adversarial Networks for Conditional Waveform Synthesis|2019|NIPS|TTS|[PDF](https://arxiv.org/pdf/1910.06711.pdf)|
|Waveglow: A flow-based generative network for speech synthesis|2019|ICASSP|TTS|[PDF](https://arxiv.org/pdf/1811.00002.pdf)|
|AutoVC: Zero-Shot Voice Style Transfer with Only Autoencoder Loss|2019|ICML|Voice Conversion|[PDF](http://proceedings.mlr.press/v97/qian19c.html)|
|LPCNet: Improving Neural Speech Synthesis Through Linear Prediction|2019|ICASSP|TTS|[PDF](https://arxiv.org/pdf/1810.11846)|
|FlowSeq: Non-Autoregressive Conditional Sequence Generation with Generative Flow|2019|EMNLP/IJCNLP|Other|[PDF](https://arxiv.org/pdf/1909.02480)|
|Flow-TTS: A Non-Autoregressive Network for Text to Speech Based on Flow|2020|ICASSP|TTS|[PDF](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9054484)|
|Fully-hierarchical fine-grained prosody modeling for interpretable speech synthesis|2020|ICASSP|TTS|[PDF](https://arxiv.org/pdf/2002.03785)|
|Location-Relative Attention Mechanisms For Robust Long-Form Speech Synthesi|2020|ICASSP|TTS|[PDF](https://arxiv.org/pdf/1910.10288)|
|A Study of Non-autoregressive Model for Sequence Generation|2020|ACL|Sequence Generation|[PDF](https://www.aclweb.org/anthology/2020.acl-main.15.pdf)|